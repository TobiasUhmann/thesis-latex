Nevertheless, a first metric, \emph{accuracy} should be defined -- a common, general metric that takes both true positives and true negatives into account equally. In case of binary classification, accuracy is the rate of correct predictions over all predictions:

\[
    Accuracy = \frac{TP + TN}{TP + TN + FP + FN}
\]

Colloquially speaking, accuracy answers the question of how good predictions are in general. In terms of the image classification example from before, classifying three out of five cat images as cats and four out of five dogs as dogs, this leads to an accuracy of $\frac{3 + 4}{3 + 4 + 2 + 1} = 0.7$. Although accuracy is a useful and intuitive metric in general, it can be misleading when it comes to inbalanced classes. For example, if nine out of ten animal photos showed dogs, a model could simply reach 90\% accuracy by always predicting the predominant dog class. To counteract this, balanced accuracy~\cite{Mower2005PREPMtPR} can be used instead. However, as mention earlier, for KGC, metrics that focus on positive predictions are preferred.
