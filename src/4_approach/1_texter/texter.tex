In practice, however, the effects of limiting the output classes are negligible as most relation-tail tuples $(rel \in Relations, tail \in Entities)$ from the theoretically vast domain $Relations \times Entities$ never occur. For example, relation-tail tuples such as $(speaks, actor)$ never occur, limiting the number of reasonable classes and thereby increasing the share of the fixed number of top classes.

The Texter's task is to take entity texts, which are usually sentences, and infer facts from them. Basically, it does so by taking a query entity's sentences and applying a multi-label classifier whose output classes correspond to facts about the entity. To be precise, the classes correspond to relation-entity tuples that form facts when the query entity is added. Figure~\ref{fig:4_approach/1_texter/texter_idea} sketches the idea by example of the entity John from the introductory chapter. In John's case the Texter would predict the facts $(John, has~gender, male)$ and $(John, speaks, Dutch)$. Experiments showed the best results when taking the relation-tail tuples that occur most often in the graph as classes. Alternatively, one could also use classes of the form $(head~entity, relation, x)$, but on the datasets considered during this thesis, such head-relation tuples were more rare than their relation-tail counterparts, leading to worse predictions. This was mostly due to concept and other common entities appearing on the tail side. For example, although facts like $(Dutch, spoken~by, John)$ are theoretically possible, that fact would usually be stored as $(John, speaks, Dutch)$. Another Texter restriction concerns the number of classes. Representing every class that could be derived from the graph is practically impossible and would lead to unreasonable training times and bad performance due to unbalanced classes. Therefore, the number of classes has been limited to 100 for the evaluated datasets, by which roughly half of the predictable facts are covered.

\begin{figure}[t]
    \centering
    \includegraphics[width=\textwidth]{4_approach/1_texter/texter_idea}
    \caption{Basic idea behind the Texter; A multi-label classifier takes a query entity $x$'s texts and predicts common facts}
    \label{fig:4_approach/1_texter/texter_idea}
\end{figure}

A straight forward implementation of the described concept leads to the \emph{simple Texter} presented in Section~\ref{subsec:4_approach/1_texter/1_simple_model}, which essentially consists of an embedding block that embeds the input sentences and a classification block that produces the output logits. What the simple Texter is missing, is the desired prioritization between the entity's sentences. This feature is added by the more complex, \emph{attentive Texter}, described in Section~\ref{subsec:4_approach/1_texter/2_attention_model}, which adds an attention mechanism between the embedding and classification blocks, that allows it to determine which sentence is most relevant for each class' prediction. That information is used in an attempt to improve the Texter's performance and returned as part of the prediction to provide the desired explanation to the user. Both, the simple and the attentive versions of the Texter, are compared in all text-related experiments in Chapter~\ref{sec:5_experiments/4_texter}, whereby the simple Texter serves as a baseline to the attentive version.

\subsection{Simple Model}
\label{subsec:4_approach/1_texter/1_simple_model}
\input{4_approach/1_texter/1_simple_model/simple_model}

\subsection{Attention Model}
\label{subsec:4_approach/1_texter/2_attention_model}
\input{4_approach/1_texter/2_attention_model/attention_model}
