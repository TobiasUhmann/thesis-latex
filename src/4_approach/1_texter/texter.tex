The Texter's task is to take entity texts, which are usually sentences, and infer facts from them. Basically, it does so by taking a query entity's sentences and applying a multi-label classifier whose output classes correspond to facts about the entity. To be precise, the classes correspond to relation-entity tuples that form facts when the query entity is added. Figure~\ref{fig:4_approach/1_texter/texter_idea} sketches the idea by example of the entity John from the introductory chapter. In John's case the Texter would predict the facts $(John, has~gender, male)$ and $(John, speaks, Dutch)$. Experiments showed the best results when taking the relation-tail tuples that occur most often in the graph as classes. Alternatively, one could also use classes of the form $(head~entity, relation, x)$, but on the datasets considered during this thesis, such head-relation tuples were more rare than their relation-tail counterparts, leading to worse predictions. This was mostly due to concept and other common entities appearing on the tail side. For example, although facts like $(Dutch, spoken~by, John)$ are theoretically possible, that fact would usually be stored as $(John, speaks, Dutch)$. Another Texter restriction concerns the number of classes. Representing every class that could be derived from the graph is practically impossible and would lead to unreasonable training times and bad performance due to unbalanced classes. Therefore, the number of classes has been limited to 100 for the evaluated datasets, by which roughly half of the predictable facts are covered.

\begin{figure}[t]
    \centering
    \includegraphics[width=\textwidth]{4_approach/1_texter/texter_idea}
    \caption{Basic idea behind the Texter; A multi-label classifier takes a query entity $x$'s texts and predicts common facts}
    \label{fig:4_approach/1_texter/texter_idea}
\end{figure}

In more detail, the Texter tokenizes the input sentences, embeds the resulting words using some NLP approach, combines each sentence's word embeddings to sentence embeddings that capture the sentences' overall meaning and passes those to the neural multi-label classifier whose output logits determine the confidence of the predicted facts. Finally, the predicted facts are sorted by confidence and returned. In addition to this \emph{simple Texter}, the more complex, \emph{attentive Texter} contains an extra attention mechanism between the embedding component and the classifier that determines which sentence is most relevant for the prediction of each class. That information is used in an attempt to improve the Texter's performance and is also passed out of the model to inform the user about that priorization. Both, the simple and attentive versions of the Texter, are compared in all text-related experiments with the simple Texter serving as a baseline to the attentive version.

\subsection{Simple Model}
\label{subsec:4_approach/1_texter/1_simple_model}
\input{4_approach/1_texter/1_simple_model/simple_model}

\subsection{Attention Model}
\label{subsec:4_approach/1_texter/2_attention_model}
\input{4_approach/1_texter/2_attention_model/attention_model}
