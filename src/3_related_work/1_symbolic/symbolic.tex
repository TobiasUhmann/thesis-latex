The classical, symbolic approach to knowledge graph completion consists of capturing patterns in the graph structure in the form of logical rules. An example of a rule would be $(X, lives~in, Netherlands) <= (X, born~in, Amsterdam)$, which states that a person born in Amsterdam lives in the Netherlands. Rules do not express absolute truths but are associated with confidences that indicate how reliable they are. For reasons of computability and runtime complexity, most rule miners restrict themselves to finding Horn rules. Although Horn rules cannot express any logical pattern, they are sufficient in practice.

The concept of logical rules is not new and has been used in inductive logic programming (ILP)~\cite{Muggleton1994InductiveLP}, such as ALEPH~\cite{ALEPH}, for a long time. However, ILP approaches do not scale very well with the size of modern knowledge graphs and mostly require negative examples, which are not given under the open-world assumption. This is where modern approaches such as the \emph{top-down} rule miner AMIE~\cite{Galrraga2013AMIEAR} and its successor AMIE+~\cite{Galrraga2015FastRM} or the \emph{bottom-up} rule miner AnyBURL~\cite{Meilicke2019AnytimeBR}, which is used in this work, come in. Thereby, top-down algorithms start their search for rules with general rules they try to find evidence for, while bottom-up approaches start with concrete paths in the graph which they try to generalize to rules.

Another way to find rules is \emph{differentiable rule mining}, implemented by neural theorem provers (NTPs)~\cite{Rocktschel2017EndtoendDP}, DRUM~\cite{Sadeghian2019DRUMED} and Neural LP~\cite{Yang2017DifferentiableLO}. These models represent rules numerically and thus enable end-to-end learning of rules. To represent a rule numerically, they encode a rule's facts as $|E| \times |E|$ matrices, that state which head entity $head \in E$ is connected to which tail entity $tail \in E$ by setting a $1$ in the matrix' respective cell. A rule is then represented by the $|E| \times |E|$ matrix calculated as the product of its facts' matrices. A limitation of the listed models is that they can only represent path-like rules.

An alternative symbolic approach to rule mining is the usage of \emph{description logics (DLs)}~\cite{Baader2003TheDL} to form so-called \emph{axioms} that capture patterns in the graph, which also have the advantage of being understandable to humans. An example of an axiom would be $Belgian \sqsubseteq DutchSpeaker \sqcup FrenchSpeaker$. As one can guess from the similarity to set operators, the axiom states that Belgians speak either Dutch, French, or both. Just like rules, those axioms are not inherently true but hold with a certain confidence. The mentioned axiom, for example, does not consider German-speaking Belgians. Two concrete axiom miners are the ones created by Völker et al.~\cite{Vlker2015AutomaticAO} and Töpper et al.~\cite{Tpper2012DBpediaOE}.
