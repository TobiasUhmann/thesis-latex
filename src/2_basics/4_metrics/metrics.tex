When designing and implementing machine learning models, scientists act on experience when it comes to architectural decisions and hyperparameter choices. In the early stages of a model, a trained eye on processing examples and observing the loss curve enable rapid progress. However, as the model matures, it becomes essential to quantify its performance with respect to comprehensive validation and test sets. Besides the selection of appropriate validation and test data, it is important to choose a meaningful metric that fits the problem. For example, when all of a models predictions are equally relevant, one would aim for an overall high precision, whereas a use case that involves a human processing the results manually, such as a web search, for example, one would choose a ranking metric that rewards good results at the top of a list. The purpose of this section is to explain those metrics relevant for this work. Section~\ref{fig:2_basics/4_metrics/1_confusion_matrix} defines basic terms used by the following sections. Sections~\ref{subsec:2_basics/4_metrics/2_accuracy} and~\ref{subsec:2_basics/4_metrics/3_prf} then present the general purpose metrics accuracy, precision, recall and F1 score while Sections~\ref{subsec:2_basics/4_metrics/4_mrr} and~\ref{subsec:2_basics/4_metrics/5_map} discuss the ranking metrics MRR and mAP\@.

\subsection{Confusion Matrix}
\label{subsec:2_basics/4_metrics/1_confusion_matrix}
\input{2_basics/4_metrics/1_confusion_matrix/confusion_matrix}

\subsection{Accuracy}
\label{subsec:2_basics/4_metrics/2_accuracy}
\input{2_basics/4_metrics/2_accuracy/accuracy}

\subsection{Precision, Recall and F1}
\label{subsec:2_basics/4_metrics/3_prf}
\input{2_basics/4_metrics/3_prf/prf}

\subsection{Mean Reciprocal Rank}
\label{subsec:2_basics/4_metrics/4_mrr}
\input{2_basics/4_metrics/4_mrr/mrr}

\subsection{Mean Average Precision}
\label{subsec:2_basics/4_metrics/5_map}
\input{2_basics/4_metrics/5_map/map}
