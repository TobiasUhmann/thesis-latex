The aggregator has the task of merging the predicted facts from Ruler and Texter. As envisioned in \autoref{sec:4_approach/3_aggregator} and illustrated in \autoref{fig:4_approach/3_aggregator/lucy}, the hope is that merging the facts leads to higher average precision because facts predicted by both components are likely to be correct and will be ranked higher. In addition, the aggregator should be able to estimate how reliable the predictions of Ruler and Texter are in relation to each other, which is done in the form of the weight parameter $\alpha$ as described in \autoref{eq:4_approach/3_aggregator/conf_aggregator}.

\autoref{tab:5_experiments/5_aggregator/results} shows the aggregator evaluation results, and thus the final evaluation results for the Power model, for a number of graph-text combinations. As fact splits, the splits with 50\% known test facts were chosen, as for the final Ruler evaluation in \autoref{sec:5_experiments/4_ruler}. The respective results for the CDE-50 and FB-50 splits from \autoref{tab:5_experiments/4_ruler/results} were taken over into \autoref{tab:5_experiments/5_aggregator/results} for easier comparability. Similarly, the chosen text sets are the one from the final Texter evaluation in \autoref{subsec:5_experiments/3_texter/3_context}. Again, \autoref{tab:5_experiments/5_aggregator/results} duplicates the respective results from \autoref{tab:5_experiments/3_texter/3_context/results} for ease of comparison. The last two columns then contain the new aggregator measurements for the combination of the corresponding Ruler and Texter.

\begin{table}[h]
    \makebox[\textwidth][c]{
        \input{5_experiments/5_aggregator/results}
    }
    \caption{Final Aggregator results, i.e. final results for the Power model. The results of the Ruler and Texter, whose predictions the Aggregator combines, are also shown for comparison. Although the Aggregator does not outperform its respective Ruler and Texter in terms of F1 score, it does for mAP.}
    \label{tab:5_experiments/5_aggregator/results}
\end{table}

As the mAP values show, the Aggregator performs several percentage points better than the Ruler and Texter on their own, with the improvement on the CDE split being more obvious. Since the mAP can only improve when prediction sets are merged, the relatively small increase on the FB split suggests that the true predictions of the Ruler and Texter almost coincide there. For the CDE, on the other hand, random sampling reveals that the improved mAPs result mainly from complementary true positives - and not so much from improved ranks of joint predictions. Looking at the values of simple and attentive Texter, it is also noticeable that the lead of the simple Texter shrinks by adding the Ruler. Likewise, the lead of the text sets with qualitative or with many sentences shrinks. Finally, the different aptitudes for Ruler and Texter on CDE and FB balance each other out, so that the aggregator results are even similar between the two splits.

Two experiments that will only be briefly mentioned here because of their unspectacular results concern the calculation of the confidence as per \autoref{eq:4_approach/3_aggregator/conf_aggregator}: First, in the beginning experiments were done with the computation of the maximum and the mean for the combined confidence, but it quickly became apparent that summing up does best accommodates the fact that a fact predicted by Ruler and Texter deserves a very high confidence. Second, taking into account the weigh parameter $\alpha$ between Ruler and Texter yields only marginal performance improvements in the tenths of a percent range, because the confidence values of Ruler and Texter seem to be very comparable after all and thus always yield $\alpha$ values close to 0.5. Strictly speaking, Ruler and Texer were both a bit too optimistic about their predictions in the experiment, so there is no imbalance between the two.
