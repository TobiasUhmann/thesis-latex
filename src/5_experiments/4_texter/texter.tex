With a Power dataset in place and the evaluatin metrics defined, the next step is training the Power model's components. In case of the Texter, however, an intermediate step is necessary. The Texter is trained in respect to a certain set of relation-tail tuples that make up its classes and requires a fixed number of sentences per entity. Given a fixed number of classes $c$, the $c$ most common relation-tail tuples in the training facts are determined and become the Texter's classes. A Texter dataset is created from the Power dataset that specifies which of the classes hold true for each entity. Furthermore, the Texter dataset contains the specified number of randomly samples sentences for each entity. Table~\ref{tab:5_experiments/4_texter/texter_dataset} shows an excerpt from a Texter dataset.

\begin{table}[h]
    \centering
    \input{5_experiments/4_texter/texter_dataset}
    \caption{Excerpt from a Texter dataset from the FB Power split and the fb-owe-1-clean text set for a Texter with eight classes}
    \label{tab:5_experiments/4_texter/texter_dataset}
\end{table}

In general, the Texter dataset's classes array is very sparse, especially for diverse knowledge graphs without frequently occurring relation-tail tuples. Therefore, it is important to weight the classes when calculating the loss during training to punish false negatives more heavily than false positives. Otherwise, the Texter would learn that always predicting 0 keeps the loss as low as possible. Table~\ref{tab:5_experiments/4_texter/classes} gives an overview of the imbalance between the top 100 classes that were selected for this evaluation. As can be seen, the FB split contains not only more facts than the CDE split, but also fewer diverse facts, which should facilitate the Texter's training.

\begin{table}[h]
    \centering
    \input{5_experiments/4_texter/classes}
    \caption{Most and least common classes on the CDE and FB splits. Frequencies are given in percent.}
    \label{tab:5_experiments/4_texter/classes}
\end{table}

Evaluation is generally performed against the Texter dataset's test subset, following the form shown in Table~\ref{tab:5_experiments/4_texter/texter_dataset}. That means that the Texter's predictions are evaluated against the classes it was trained on and that the results are comparable to the validation results during training. The metrics chosen are macro precision, recall and F1 over the classes. This is rather demanding, as rare classes are equally weighted as the common classes, that represent more facts, but it follows the objective of predicting all classes as good as possible. For the final comparison with Ruler and Aggregator, however, the Texter is also evaluated against the Power split's test facts, which includes facts the Texter is unable to predict, using the common metrics discussed before in Section~\ref{sec:5_experiments/3_metrics}.

The following Subsection~\ref{subsec:5_experiments/4_texter/1_zero_rule} applies the presented metrics to several baselines to give an idea of the problem's complexity. Given the reference values from the baselines, Subsections~\ref{subsec:5_experiments/4_texter/2_static} and~\ref{subsec:5_experiments/4_texter/3_context} present two ways of implementing the Texter's embedding block using static and contextual word embeddings, whereby the latter is used in the final Power implementation described in Chapter~\ref{ch:4_approach}. To distinguish the two variants, they are also referred to as static and contextual Texter, respectively. Both sections include several experiments that led to the final versions of the models. In addition, each experiment compares the simple and the attentive versions of the Texter to see which variations affect the attention mechanism of the latter.

\subsection{Zero Rule Baselines}
\label{subsec:5_experiments/4_texter/1_zero_rule}
\input{5_experiments/4_texter/1_zero_rule/zero_rule}

\subsection{Static Word Embeddings}
\label{subsec:5_experiments/4_texter/2_static}
\input{5_experiments/4_texter/2_static/static}

\subsection{Contextual Word Embeddings}
\label{subsec:5_experiments/4_texter/3_context}
\input{5_experiments/4_texter/3_context/context}
