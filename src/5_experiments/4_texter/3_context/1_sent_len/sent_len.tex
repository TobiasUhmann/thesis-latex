bert takes batch of fixed length sents, longer sents are cut, shorter sents are padded
still, last tok is always [SEP], despite cut. also first is [CLS]
mask specifies which tokens are words and which are padding
example: ["short sent", "long sent"] become ...
depending on max sent len, more or less tokens are lost
tried several sent lengths as shown in table \ref{tab:5_experiments/4_texter/3_context/1_sent_len/grid_search}

\begin{table}[h]
    \centering
    \input{5_experiments/4_texter/3_context/1_sent_len/grid_search}
    \caption{Sent len}
    \label{tab:5_experiments/4_texter/3_context/1_sent_len/grid_search}
\end{table}

result is that performance increases strongly first until certain point where does not really matter anymore
decided to go with 64
