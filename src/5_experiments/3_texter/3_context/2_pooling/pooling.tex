The switch to DistilBert also opens up new possibilities for the embedding block's pooling layer. Although, after the experiments on static word embeddings, the choice of mean pooling remains, there are now several possibilities which embeddings to average. As mentioned before, DistilBERT adds the [CLS] token to the input sentence. The purpose of this token is to capture the meaning of the sentence, which is what it is used for in the BERT paper. According to reports from various online forums, however, models achieved better results by using the means of the actual word embedding instead of the [CLS] embedding. Therefore, it was tested which variant works better for the Power model. \autoref{tab:5_experiments/3_texter/3_context/2_pooling/grid_search} shows the results, referring to the word embeddings as ``Words''. While on it, two further variants were tested, namely averaging all of the mentioned embeddings, that is the word embeddings plus the [CLS] embedding, and averaging all embeddings including those for the padding tokens. Those two variants are referred to as ``All'' and ``Pad'' in \autoref{tab:5_experiments/3_texter/3_context/2_pooling/grid_search}.

\begin{table}[h]
    \centering
    \input{5_experiments/3_texter/3_context/2_pooling/grid_search}
    \caption{Contextual Texters using various pooling methods. Sentence embeddings can be created by taking the [CLS] token's embedding (CLS), averaging the words' embeddings (Words), averaging the words' embeddings, including the [CLS] token (C+W), or by averaging all token embeddings, including embedded paddings (C+W+P). Overall, the choice does not make a big difference.}
    \label{tab:5_experiments/3_texter/3_context/2_pooling/grid_search}
\end{table}

Apparently, however, the difference between the approaches is negligable on all text sets. The involvement of all word embeddings plus the [CLS] embedding seems to yield minimally better results than the other approaches, so it has been set as the default pooling strategy.
